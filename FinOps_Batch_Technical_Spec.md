# üß± Sp√©cification Technique ‚Äì FinOps Batch (Quarkus)

## 1. Port√©e

Ce document d√©crit le **microservice FinOps Batch** charg√© de :
- Collecter / calculer les consommations et co√ªts FinOps par **domaine technologique** (Open/Legacy, Cloud Priv√©, Cloud Public, Natif).
- Normaliser ces donn√©es sous forme de **relev√©s mensuels** par application et par produit.
- Charger les relev√©s dans **PostgreSQL** (data mart FinOps).
- Rafra√Æchir les **materialized views** utilis√©es par l‚ÄôAPI / Backstage.
- Assurer tra√ßabilit√©, idempotence, reprocess et observabilit√©.

---

## 2. Hypoth√®ses & Principes

- **Granularit√© principale : mensuelle** (`period_month`).
- Ex√©cution **nightly** (toutes les nuits) avec recalcul de la fen√™tre ¬´ mois courant ¬ª (et √©ventuellement N-1).
- Le batch est **idempotent** au niveau de la p√©riode (recalcul complet par p√©riode).
- Les sources peuvent √™tre h√©t√©rog√®nes ; la sortie est un **contrat unique** : `Relev√©`.
- Les vues mat√©rialis√©es sont **d√©clar√©es via migrations** et **refresh** en fin de run.

---

## 3. Stack Technique

### 3.1 Runtime
- **Quarkus** (Java 17)
- Packaging : JVM (recommand√©) ou native (optionnel selon contraintes d‚Äôinfra)
- Build : Maven + Quarkus plugin

### 3.2 Acc√®s donn√©es
- PostgreSQL : `quarkus-jdbc-postgresql` + ORM l√©ger (JDBC / Panache / JOOQ selon choix)
- MongoDB (Raw CMDB) : `quarkus-mongodb-client` (lecture uniquement c√¥t√© batch)

### 3.3 HTTP & S√©curit√©
- `quarkus-rest` / `quarkus-rest-client` pour appeler les APIs (Cloud/Services natifs)
- Auth :
  - OIDC client credentials / service account (Keycloak) **ou**
  - Token technique (vault/secret) selon SI
- TLS / certs : gestion via truststore container + secrets

### 3.4 Scheduling & Ex√©cution
**Recommandation : Kubernetes CronJob**
- Un pod lanc√© chaque nuit
- Ex√©cute le pipeline
- Se termine (pas de service permanent)

Alternative : service permanent + `quarkus-scheduler` (si CronJob non possible).

### 3.5 Observabilit√©
- Logs structur√©s JSON (ou format standard entreprise)
- Metrics Prometheus : dur√©e run, volumes, erreurs
- Tracing (optionnel) : OpenTelemetry

---

## 4. Architecture du Service

### 4.1 Composants principaux

- **BatchRunner** : point d‚Äôentr√©e du run (orchestration globale)
- **Domain Batches** (4 familles) :
  - `OpenLegacyBatch` (Mongo Raw CMDB ‚Üí Relev√©s)
  - `PrivateCloudBatch` (APIs internes ‚Üí Relev√©s)
  - `PublicCloudBatch` (APIs fournisseurs ‚Üí Relev√©s)
  - `NativeCostsBatch` (services natifs : Cube/GitLab/Artifactory ‚Üí Relev√©s)
- **ReleveWriter** : persistance en PostgreSQL
- **RunRepository** : gestion `etl_runs` (runId, statut, timings, volumes)
- **MvRefresher** : refresh des materialized views
- **ReprocessController** (optionnel) : endpoint interne pour relancer une p√©riode (si besoin)

### 4.2 Contrat de sortie : Relev√© (concept technique)

Un relev√© est un enregistrement normalis√© qui identifie :
- `period_month`
- `application_id` (ou identifiant stable d‚Äôapplication)
- `product_id`
- (d√©riv√©s / ou stock√©s) `family_id`, `domain_id`
- `usage_quantity`
- `unit_cost`
- `total_cost`
- `source`
- `run_id`
- timestamps de calcul

---

## 5. Orchestration d‚Äôun Run

### 5.1 Fen√™tre de calcul
- Par d√©faut : `period_month = current_month`
- Optionnel : recalcul `current_month` + `previous_month` (gestion data tardive)

### 5.2 √âtapes du pipeline (workflow technique)

1) **Init run**
- Cr√©er `run_id`
- Ins√©rer ligne `etl_runs` : status = `RUNNING`, start_time
- R√©soudre la/les p√©riodes cibl√©es

2) **Extraction / Calcul par domaine**
Pour chaque domaine activ√© :
- Lire source (Mongo ou APIs)
- Mapper vers objets m√©tier interm√©diaires
- Calculer usage + co√ªts
- Produire une liste de `Relev√©`

3) **Load Postgre (idempotent)**
Pour chaque p√©riode cibl√©e :
- `DELETE` des relev√©s existants (ou `DELETE` par run+period) puis r√©insertion
  - strat√©gie recommand√©e : supprimer par `period_month` et `source` (ou `domain`) avant insert
- Insert en bulk (batch insert) dans `fact_releve`

4) **Refresh materialized views**
- Refresh des MVs n√©cessaires (ordre d√©fini)
- Utiliser `CONCURRENTLY` si index uniques en place

5) **Finalize run**
- Update `etl_runs` : status = `SUCCESS`, end_time, volumes, erreurs=0
- En cas d‚Äôerreur : status=`FAILED` + stack/summary + end_time

---

## 6. Idempotence & Reprocess

### 6.1 Strat√©gie recommand√©e
- **Rebuild complet** d‚Äôune p√©riode au lieu d‚Äôupsert incr√©mental
- Pour reprocess :
  - m√™me pipeline, m√™me p√©riode
  - suppression + r√©insertion

### 6.2 Table de suivi `etl_runs`
Champs typiques :
- `run_id` (PK)
- `status` (RUNNING/SUCCESS/FAILED)
- `periods` (ex: JSON array)
- `started_at`, `ended_at`
- `records_inserted`
- `errors_count`
- `error_summary` (texte court)
- `trigger_type` (CRON / MANUAL)
- `git_sha` / `version` (optionnel mais tr√®s utile)

---

## 7. Gestion des erreurs & Robustesse

### 7.1 Politique d‚Äô√©chec
- Si un domaine √©choue :
  - Option A (strict) : run FAILED, rien n‚Äôest publi√©
  - Option B (tol√©rant) : domain FAILED mais run SUCCESS partiel (√† √©viter en v1)

Recommandation : **strict** en v1 (coh√©rence data).

### 7.2 Retries
- Retries r√©seau sur appels API (timeout, 5xx)
- Circuit breaker / backoff (MicroProfile Fault Tolerance si autoris√©)

### 7.3 Timeouts
- D√©finir des timeouts par client HTTP
- Timeouts DB (pool) et taille de batch d‚Äôinsert

---

## 8. Refresh des Materialized Views

### 8.1 Orchestration
- `MvRefresher` ex√©cute un ordre d√©terministe :
  1. MVs socle (domain/family/app)
  2. MVs drill-down
  3. MVs ranking/anomalies
  4. MVs history (si activ√©es)

### 8.2 Exemple
- `mv_cost_domain_month`
- `mv_cost_family_month`
- `mv_cost_application_month`
- `mv_cost_app_domain_month`
- `mv_cost_app_family_month`
- `mv_cost_app_product_month`
- `mv_rank_app_month`
- `mv_anomalies_month`
- `mv_history_domain`

---

## 9. Configuration (Quarkus)

### 9.1 Variables d‚Äôenvironnement (exemples)
- `FINOPS_PERIOD_MODE=current|range`
- `FINOPS_RECALC_PREVIOUS_MONTH=true|false`
- `FINOPS_DOMAINS_ENABLED=open,private,public,native`
- `POSTGRES_URL`, `POSTGRES_USER`, `POSTGRES_PASSWORD`
- `MONGO_URL`, `MONGO_DB`
- `OIDC_TOKEN_URL`, `OIDC_CLIENT_ID`, `OIDC_CLIENT_SECRET`
- `HTTP_TIMEOUT_MS`, `HTTP_RETRIES`

### 9.2 Feature flags
Permettre d‚Äôactiver/d√©sactiver des domaines sans rebuild d‚Äôimage.

---

## 10. Ex√©cution & D√©ploiement

### 10.1 Mode recommand√© : Kubernetes CronJob

- Image : `finops-batch-ms:<version>`
- Schedule : nightly (ex: `0 2 * * *`)
- ConcurrencyPolicy : `Forbid` (√©vite 2 runs en parall√®le)
- Resources : requests/limits adapt√©s aux volumes
- Secrets : DB creds, OIDC creds, TLS certs
- NetworkPolicy : acc√®s DB + APIs uniquement

### 10.2 Alternative : Service permanent
- Deployment + `quarkus-scheduler`
- Moins clean (process toujours actif) mais simple si CronJob interdit

---

## 11. Performance (recommandations)

- Utiliser inserts batch (JDBC batch size)
- Indexer `fact_releve` sur `(period_month, application_id)`, `(period_month, domain_id)`, etc.
- Limiter refresh MV √† la fen√™tre recalcul√©e si possible (sinon refresh complet acceptable en v1)
- Pr√©voir partitionnement mensuel de `fact_releve` si volumes tr√®s √©lev√©s

---

## 12. S√©curit√©

- Identit√© technique (service account) pour appels API
- Stockage secrets : Kubernetes Secrets / Vault
- Aucun secret en logs
- TLS syst√©matique (HTTPs) + truststore √† jour

---

## 13. Livrables attendus (tech)

- Projet Quarkus `finops-batch-ms`
- Modules par domaine (packages s√©par√©s)
- Migrations DB (si batch porte aussi les migrations) ou d√©pendance √† un module DB d√©di√©
- Helm chart / manifests CronJob
- Dashboards/alerting minimal : run failed, dur√©e anormale, volume anormal

---

## 14. Points ouverts (√† trancher)

- Identifiant stable d‚Äôapplication (UUID interne vs name)
- Politique tol√©rance √©chec multi-domaines (strict vs partial)
- Rafra√Æchissement MV complet vs partiel
- Stockage famille/domaine d√©normalis√© dans `fact_releve` ou via dimension

---

## 15. R√©sum√©

Le FinOps Batch est un **ETL nightly** orchestr√© sous Quarkus, ex√©cut√© id√©alement via **Kubernetes CronJob**.  
Il normalise des sources h√©t√©rog√®nes en **relev√©s mensuels** stock√©s dans PostgreSQL, puis rafra√Æchit des **materialized views** consomm√©es par l‚ÄôAPI FinOps et Backstage.
